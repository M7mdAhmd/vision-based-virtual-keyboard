# Vision-Based Virtual Keyboard

A contactless virtual keyboard system that uses a webcam to detect hand movements and interpret finger gestures as keystrokes. Built with MediaPipe for real-time hand tracking and OpenCV for UI rendering, the system enables users to type using simple gestures like pointing and pinching. This project offers a hygienic, accessible alternative to traditional physical or touchscreen keyboards, with applications in assistive technology, AR/VR, and sterile environments.

## Features

- Real-time hand detection and tracking
- Gesture-based typing using fingertip and pinch detection
- On-screen visual feedback for key highlighting and selection
- Custom virtual keyboard drawn using OpenCV
- Text output buffer displayed live

## Tech Stack

- Python
- OpenCV
- MediaPipe
- NumPy

## Applications

- Accessibility tools for users with motor impairments
- Touchless input in hospitals, clean rooms, and labs
- Non-contact interaction in public kiosks
- Gesture control in AR/VR environments
- Smart home interfaces

## Project Team

- [Mohamed Ahmed Elshoraky](http://www.linkedin.com/in/mohamed-elshoraky)
- [Omar Alaa Zalat](https://www.linkedin.com/in/omar-alaa-20o04?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)
- [Mahmoud Ibrahim Tawfik](https://www.linkedin.com/in/mahmoud-tawfik-103643235/)
- [Moaz Loaie Mohamed](https://www.linkedin.com/in/moaz-loaie?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)
